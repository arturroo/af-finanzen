{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983af335",
   "metadata": {},
   "source": [
    "## Iteration1 Feature Engineering with TensorFlow\n",
    "\n",
    "# Plan na bazie MLE4.3.(5,6,7,8,9)\n",
    "1. Floats change into categorical bins (MLE 4.3.1) - quntiles with same number of examples per bin? \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c9431",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14462f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730fa8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client library version: 3.34.0\n",
      "Tensorflow version: 2.18.1\n",
      "Pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "from tensorflow import feature_column as fc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"BigQuery client library version: {bigquery.__version__}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1ed39",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3654d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project=\"af-finanzen\")\n",
    "query = \"\"\"SELECT\n",
    "      type\n",
    "    , started\n",
    "    , description\n",
    "    , amount\n",
    "    , fee\n",
    "    , currency\n",
    "    , state\n",
    "    , account\n",
    "    , month\n",
    "    , CASE\n",
    "      WHEN i1_true_label = 'PK Prezenty' THEN 'PK Rest'\n",
    "      WHEN i1_true_label = 'Apt' THEN 'PK Kasia'\n",
    "      ELSE i1_true_label\n",
    "      END AS i1_true_label\n",
    "FROM `af-finanzen.monatsabschluss.revolut_abrechnung`\n",
    "\"\"\"\n",
    "df = bq.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489193a9",
   "metadata": {},
   "source": [
    "# Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47a7749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652 train examples\n",
      "413 validation examples\n",
      "517 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2) # val is 16% from df, train 74%\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94939d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/transak-i1-train.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "846250d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv('data/transak-i1-val.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f2b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/transak-i1-test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== data/transak-i1-train.csv =====\n",
      "===== data/transak-i1-val.csv =====\n",
      "===== data/transak-i1-test.csv =====\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def head(filename, lines=10):\n",
    "  \"\"\"Prints the first 'lines' lines of the file.\"\"\"\n",
    "  with open(filename, 'r') as f:\n",
    "    for line in itertools.islice(f, lines):\n",
    "      print(line, end='') # Use end='' to avoid extra newlines\n",
    "  print(f\"\\n\")\n",
    "\n",
    "for file in [\"data/transak-i1-train.csv\", \"data/transak-i1-val.csv\", \"data/transak-i1-test.csv\"]:\n",
    "  print(f\"==> {file} <==\")\n",
    "  #head(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b4ca3",
   "metadata": {},
   "source": [
    "## TF Dataset from Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba8316f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2dataset(df: pd.DataFrame, shuffle=True, batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(\"i1_true_label\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices(dict(df), labels)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df), seed=42)\n",
    "    # ds.map(lambda...) M3.2\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de693d57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:105\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    104\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     spec = type_spec_from_value(t, use_fallback=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    107\u001b[39m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[32m    108\u001b[39m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:514\u001b[39m, in \u001b[36mtype_spec_from_value\u001b[39m\u001b[34m(element, use_fallback)\u001b[39m\n\u001b[32m    511\u001b[39m     logging.vlog(\n\u001b[32m    512\u001b[39m         \u001b[32m3\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mtype\u001b[39m(element).\u001b[34m__name__\u001b[39m, e))\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    515\u001b[39m     element,\n\u001b[32m    516\u001b[39m     \u001b[38;5;28mtype\u001b[39m(element).\u001b[34m__name__\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: Could not build a `TypeSpec` for 1731   2022-07-16 07:39:18+00:00\n1638   2025-02-19 15:39:04+00:00\n1167   2021-07-10 17:32:48+00:00\n1507   2023-03-27 15:21:16+00:00\n1966   2023-05-29 10:15:12+00:00\n                  ...           \n305    2023-04-12 12:16:43+00:00\n2385   2021-10-15 17:11:00+00:00\n1843   2021-11-06 15:21:50+00:00\n778    2024-06-08 12:10:53+00:00\n1294   2024-10-14 10:17:04+00:00\nName: started, Length: 1652, dtype: datetime64[us, UTC] with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_ds = df2dataset(train)\n\u001b[32m      2\u001b[39m val_ds = df2dataset(val, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mdf2dataset\u001b[39m\u001b[34m(df, shuffle, batch_size)\u001b[39m\n\u001b[32m      2\u001b[39m df = df.copy()\n\u001b[32m      3\u001b[39m labels = df.pop(\u001b[33m\"\u001b[39m\u001b[33mi1_true_label\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ds = tf.data.Dataset.from_tensor_slices(\u001b[38;5;28mdict\u001b[39m(df), labels)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m      6\u001b[39m     ds = ds.shuffle(buffer_size=\u001b[38;5;28mlen\u001b[39m(df), seed=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:827\u001b[39m, in \u001b[36mDatasetV2.from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m from_tensor_slices_op._from_tensor_slices(tensors, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:25\u001b[39m, in \u001b[36m_from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensor_slices\u001b[39m(tensors, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _TensorSliceDataset(tensors, name=name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_tensor_slices_op.py:33\u001b[39m, in \u001b[36m_TensorSliceDataset.__init__\u001b[39m\u001b[34m(self, element, is_files, name)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   element = structure.normalize_element(element)\n\u001b[32m     34\u001b[39m   batched_spec = structure.type_spec_from_value(element)\n\u001b[32m     35\u001b[39m   \u001b[38;5;28mself\u001b[39m._tensors = structure.to_batched_tensor_list(batched_spec, element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:110\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    105\u001b[39m     spec = type_spec_from_value(t, use_fallback=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    107\u001b[39m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[32m    108\u001b[39m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[32m    109\u001b[39m   normalized_components.append(\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m       ops.convert_to_tensor(t, name=\u001b[33m\"\u001b[39m\u001b[33mcomponent_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % i))\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[32m    113\u001b[39m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[32m    114\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m spec.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mDatasetSpec\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:732\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    731\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry.convert(\n\u001b[32m    733\u001b[39m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[32m    734\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_tensor_conversion.py:29\u001b[39m, in \u001b[36m_constant_tensor_conversion_function\u001b[39m\u001b[34m(v, dtype, name, as_ref)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     28\u001b[39m _ = as_ref\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m constant_op.constant(v, dtype=dtype, name=name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    277\u001b[39m                         allow_broadcast=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m    291\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    292\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    293\u001b[39m )\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(\n\u001b[32m    298\u001b[39m     ctx, value, dtype, shape, verify_shape\n\u001b[32m    299\u001b[39m ) -> ops._EagerTensorBase:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m   t = convert_to_eager_tensor(value, ctx, dtype)\n\u001b[32m    302\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\mambaforge\\envs\\tf_py311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    107\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "\u001b[31mValueError\u001b[39m: Failed to convert a NumPy array to a Tensor (Unsupported object type Timestamp)."
     ]
    }
   ],
   "source": [
    "train_ds = df2dataset(train)\n",
    "val_ds = df2dataset(val, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
