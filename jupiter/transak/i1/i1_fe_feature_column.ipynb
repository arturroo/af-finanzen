{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983af335",
   "metadata": {},
   "source": [
    "# Transak iteration 1\n",
    "Feature Engineering with TensorFlow using old API tf.feature_column\n",
    "\n",
    "## I used knowledge from those courses \n",
    "- GCP Proffesional Machine Learning Engineer course 4 Feature Engineering, modules 3,5,6,7,8,9\n",
    "- Machine Learning Mastery course from Adam Dobrakowski\n",
    "\n",
    "## Assumptions\n",
    "1. Floats change into categorical bins (MLE 4.3.1) - quntiles with same number of examples per bin? - perhaps in next iteration with Keras or tf.Transform. Now I need fast next level from benchmark model.\n",
    "2. Cyclic transformation of dates should allow better identify Abos\n",
    "3. Environment installation:\n",
    "   - anaconda: Python 3.9\n",
    "   - pip: db-dtypes==1.0.5, google-cloud-bigquery==3.9.0, pandas==1.5.3, numpy==1.23.5, tensorflow==2.12.1 - this setup supports old tf.feature_column API and Keras DenseFeatures layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c9431",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14462f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730fa8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client library version: 3.9.0\n",
      "Tensorflow version: 2.12.1\n",
      "Pandas version: 1.5.3\n",
      "Keras version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import feature_column as fc\n",
    "\n",
    "print(f\"BigQuery client library version: {bigquery.__version__}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Keras version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1ed39",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3654d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project=\"af-finanzen\")\n",
    "query = \"\"\"\n",
    "  WITH EDA AS (\n",
    "    SELECT\n",
    "        tid\n",
    "      , type\n",
    "      --AF20250604 I need Cyclic because of minmax normalization , UNIX_SECONDS(started) started -- TF works with numbers or strings, not with timestamps\n",
    "      --AF20250604 I need Cyclic because of minmax normalization , UNIX_SECONDS(first_started) first_started -- this should be part of feature engineering or ingestion ale update?\n",
    "      --AF20250604 I need Cyclic because of minmax normalization   -- if this is here, then it is easier do train test eval split because here it is done on all data,\n",
    "      --AF20250604 I need Cyclic because of minmax normalization   -- an not on train or test or validation separately where it would be different. Same for min max and so on.. \n",
    "      , started\n",
    "      , first_started\n",
    "      , LOWER(description) description -- i1_eda_conclusion_2\n",
    "      , amount\n",
    "      , fee\n",
    "      , currency\n",
    "      , state\n",
    "      , account\n",
    "      , CASE\n",
    "          WHEN i1_true_label = 'PK Prezenty' THEN 'PK Rest'\n",
    "          WHEN i1_true_label = 'Apt' THEN 'PK Kasia'\n",
    "          ELSE i1_true_label\n",
    "        END AS i1_true_label\n",
    "    FROM `af-finanzen.monatsabschluss.revolut_abrechnung`\n",
    "    WHERE\n",
    "      type != \"FEE\" -- i1_eda_conclusion_1\n",
    "    ORDER BY started\n",
    "  ),\n",
    "  LABEL_INT AS (\n",
    "    SELECT\n",
    "      *\n",
    "      , DENSE_RANK() OVER(ORDER BY i1_true_label) - 1 AS i1_true_label_id\n",
    "    FROM EDA\n",
    "  ),\n",
    "  SPLIT_SET AS (\n",
    "    SELECT\n",
    "        tid\n",
    "      , i1_true_label\n",
    "      , CASE\n",
    "          WHEN ABS(MOD(tid, 10)) < 8 THEN 'train'\n",
    "          WHEN ABS(MOD(tid, 10)) = 8 THEN 'validation'\n",
    "          WHEN ABS(MOD(tid, 10)) = 9 THEN 'test'\n",
    "          -- WHEN ABS(MOD(tid, 100)) < 70 THEN 'train'\n",
    "          -- WHEN ABS(MOD(tid, 100)) BETWEEN 70 AND 85 THEN 'validation'\n",
    "          -- WHEN ABS(MOD(tid, 100)) BETWEEN 86 AND 100 THEN 'test'\n",
    "          ELSE \"unknown\"\n",
    "        END AS split_set\n",
    "    FROM EDA\n",
    "    GROUP BY\n",
    "      i1_true_label, tid\n",
    "  )\n",
    "  SELECT\n",
    "    LABEL_INT.* EXCEPT(tid, i1_true_label)\n",
    "    , SPLIT_SET.split_set\n",
    "  FROM LABEL_INT\n",
    "  JOIN SPLIT_SET\n",
    "  ON LABEL_INT.tid = SPLIT_SET.tid\n",
    "\"\"\"\n",
    "df = bq.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733465c",
   "metadata": {},
   "source": [
    "Back mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9096534e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i1_true_label</th>\n",
       "      <th>i1_true_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exchange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PK Abo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PK Artur</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PK Auto</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PK Kasia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PK Leben</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PK Maja</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PK Medic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PK Reisen</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PK Rest</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SK Ferien</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SK Haushalt</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Top-Up</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eShop</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i1_true_label  i1_true_label_id\n",
       "0       Exchange                 0\n",
       "1         PK Abo                 1\n",
       "2       PK Artur                 2\n",
       "3        PK Auto                 3\n",
       "4       PK Kasia                 4\n",
       "5       PK Leben                 5\n",
       "6        PK Maja                 6\n",
       "7       PK Medic                 7\n",
       "8      PK Reisen                 8\n",
       "9        PK Rest                 9\n",
       "10     SK Ferien                10\n",
       "11   SK Haushalt                11\n",
       "12        Top-Up                12\n",
       "13         eShop                13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "  WITH EDA AS (\n",
    "    SELECT\n",
    "        CASE\n",
    "          WHEN i1_true_label = 'PK Prezenty' THEN 'PK Rest'\n",
    "          WHEN i1_true_label = 'Apt' THEN 'PK Kasia'\n",
    "          ELSE i1_true_label\n",
    "        END AS i1_true_label\n",
    "    FROM `af-finanzen.monatsabschluss.revolut_abrechnung`\n",
    "    WHERE\n",
    "      type != \"FEE\" -- i1_eda_conclusion_1\n",
    "    ORDER BY started\n",
    "  )\n",
    "  SELECT\n",
    "    DISTINCT i1_true_label,\n",
    "    DENSE_RANK() OVER (ORDER BY i1_true_label) - 1 AS i1_true_label_id\n",
    "  FROM EDA\n",
    "  ORDER BY i1_true_label\n",
    "\"\"\"\n",
    "rev_mapping_df = bq.query(query).to_dataframe()\n",
    "rev_mapping_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13918f4",
   "metadata": {},
   "source": [
    "# Cyclic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c99d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['started_day'] = df.started.dt.day\n",
    "df['started_day_sin'] = np.sin((df.started_day-1)*(2.*np.pi/31))\n",
    "df['started_day_cos'] = np.cos((df.started_day-1)*(2.*np.pi/31))\n",
    "df['started_month'] = df.started.dt.month\n",
    "df['started_month_sin'] = np.sin((df.started_month-1)*(2.*np.pi/12))\n",
    "df['started_month_cos'] = np.cos((df.started_month-1)*(2.*np.pi/12))\n",
    "# can not by normalized df['started_year'] = df.started.dt.year\n",
    "df.drop(columns=['started'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4edcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_started_day'] = df.first_started.dt.day\n",
    "df['first_started_day_sin'] = np.sin((df.first_started_day-1)*(2.*np.pi/31))\n",
    "df['first_started_day_cos'] = np.cos((df.first_started_day-1)*(2.*np.pi/31))\n",
    "df['first_started_month'] = df.first_started.dt.month\n",
    "df['first_started_month_sin'] = np.sin((df.first_started_month-1)*(2.*np.pi/12))\n",
    "df['first_started_month_cos'] = np.cos((df.first_started_month-1)*(2.*np.pi/12))\n",
    "df['first_started_year'] = df.first_started.dt.year\n",
    "df.drop(columns=['first_started'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489193a9",
   "metadata": {},
   "source": [
    "# Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47a7749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2581, 22) all examples and columns\n",
      "2093 train examples\n",
      "251 test examples\n",
      "237 validation examples\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['split_set'] == 'train'].drop(columns=['split_set'])\n",
    "test_df = df[df['split_set'] == 'test'].drop(columns=['split_set'])\n",
    "val_df = df[df['split_set'] == 'validation'].drop(columns=['split_set'])\n",
    "print(df.shape, 'all examples and columns')\n",
    "print(len(train_df), 'train examples')\n",
    "print(len(test_df), 'test examples')\n",
    "print(len(val_df), 'validation examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b4ca3",
   "metadata": {},
   "source": [
    "## Transform Pandas DF into Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8316f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2dataset(df: pd.DataFrame, shuffle=True, batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(\"i1_true_label_id\").astype(np.int64)\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, pd.Int64Dtype):\n",
    "            # It's often safest to convert feature columns to float32,\n",
    "            # as it naturally handles potential missing values if you need them.\n",
    "            # also solves ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type int).\n",
    "            print(f\"Converting feature column '{col}' from Int64 to float32.\")\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df), seed=42)\n",
    "    # ds.map(lambda...) M3.2\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de693d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of feature names: ['type', 'description', 'amount', 'fee', 'currency', 'state', 'account', 'started_day', 'started_day_sin', 'started_day_cos', 'started_month', 'started_month_sin', 'started_month_cos', 'first_started_day', 'first_started_day_sin', 'first_started_day_cos', 'first_started_month', 'first_started_month_sin', 'first_started_month_cos', 'first_started_year']\n",
      "Batch of type: [b'TOPUP' b'CARD_PAYMENT' b'CARD_PAYMENT' b'TOPUP' b'CARD_PAYMENT'\n",
      " b'CARD_PAYMENT' b'TOPUP' b'CARD_PAYMENT' b'CARD_PAYMENT' b'CARD_PAYMENT'\n",
      " b'TOPUP' b'CARD_PAYMENT' b'CARD_PAYMENT' b'CARD_PAYMENT' b'CARD_PAYMENT'\n",
      " b'TOPUP' b'TOPUP' b'TOPUP' b'CARD_PAYMENT' b'CARD_PAYMENT' b'TOPUP'\n",
      " b'CARD_PAYMENT' b'TOPUP' b'TOPUP' b'TOPUP' b'CARD_PAYMENT'\n",
      " b'CARD_PAYMENT' b'TOPUP' b'CARD_PAYMENT' b'TRANSFER' b'CARD_PAYMENT'\n",
      " b'TOPUP']\n",
      "Batch of labels: [12  5  8 12  5  5 12  5  5  6 12 13 11  2  5 12 12 12  2  2 12  5 12 12\n",
      " 12 13  5 12  2  5  5 12]\n"
     ]
    }
   ],
   "source": [
    "train_ds = df2dataset(train_df)\n",
    "val_ds = df2dataset(val_df, shuffle=True)\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print(f'List of feature names: {list(feature_batch.keys())}')\n",
    "    print(f'Batch of type: {feature_batch[\"type\"]}')\n",
    "    print(f'Batch of labels: {label_batch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224a625",
   "metadata": {},
   "source": [
    "# Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57bcc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812c750",
   "metadata": {},
   "source": [
    "Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18a525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col_names_normalized = ['started_day_sin', 'started_day_cos', 'started_month_sin', 'started_month_cos', 'first_started_day_sin', 'first_started_day_cos', 'first_started_month_sin', 'first_started_month_cos']\n",
    "numerical_col_names_to_normalize = ['amount', 'fee', 'started_day', 'started_month', 'first_started_day', 'first_started_month', 'first_started_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09849043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28456\\792557420.py:2: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "for feature_name in numerical_col_names_normalized:\n",
    "    feature_columns.append(fc.numeric_column(feature_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330a5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS = {}\n",
    "for feature in numerical_col_names_to_normalize:\n",
    "    min_val = train_df[feature].min()\n",
    "    max_val = train_df[feature].max()\n",
    "    \n",
    "    STATS[feature] = {\n",
    "        'min': min_val,\n",
    "        'max': max_val\n",
    "    }\n",
    "\n",
    "def get_scaling_fn(feature: str):\n",
    "    def minmax(x):\n",
    "        mini = STATS[feature]['min']\n",
    "        maxi = STATS[feature]['max']\n",
    "        return (x-mini)/(maxi-mini + 1e-7)\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c72bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in numerical_col_names_to_normalize:\n",
    "    scaling_fn = get_scaling_fn(feature_name)\n",
    "    feature_columns.append(fc.numeric_column(feature_name, normalizer_fn=scaling_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383873f3",
   "metadata": {},
   "source": [
    "Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8fec63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28456\\2705598244.py:5: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28456\\2705598244.py:6: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['type', 'description', 'currency', 'state', 'account']\n",
    "tobe_crossed = []\n",
    "for feature_name in categorical_columns:\n",
    "    vocabulary = df[feature_name].unique()\n",
    "    feature_column = fc.categorical_column_with_vocabulary_list(feature_name, vocabulary, num_oov_buckets=1)\n",
    "    feature_columns.append(fc.indicator_column(feature_column))\n",
    "    if feature_name in ['type', 'description']:\n",
    "        tobe_crossed.append(feature_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01fb37a",
   "metadata": {},
   "source": [
    "Crossed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb28cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28456\\1641635335.py:1: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
     ]
    }
   ],
   "source": [
    "type_description_cross = fc.crossed_column(tobe_crossed, hash_bucket_size=100)\n",
    "type_description_cross = fc.indicator_column(type_description_cross)\n",
    "feature_columns.append(type_description_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924d61e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a4005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'type': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=string>, 'description': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'amount': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'fee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'currency': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'state': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=string>, 'account': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'started_day': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=int64>, 'started_day_sin': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'started_day_cos': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'started_month': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'started_month_sin': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'started_month_cos': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'first_started_day': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'first_started_day_sin': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'first_started_day_cos': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'first_started_month': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'first_started_month_sin': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'first_started_month_cos': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'first_started_year': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'type': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=string>, 'description': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'amount': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'fee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'currency': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'state': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=string>, 'account': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'started_day': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=int64>, 'started_day_sin': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'started_day_cos': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'started_month': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'started_month_sin': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'started_month_cos': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'first_started_day': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'first_started_day_sin': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'first_started_day_cos': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'first_started_month': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'first_started_month_sin': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'first_started_month_cos': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'first_started_year': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "48/66 [====================>.........] - ETA: 0s - loss: 2.1694 - accuracy: 0.3776WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'type': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=string>, 'description': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'amount': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float64>, 'fee': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float64>, 'currency': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'state': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=string>, 'account': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'started_day': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=int64>, 'started_day_sin': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float64>, 'started_day_cos': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float64>, 'started_month': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=int64>, 'started_month_sin': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float64>, 'started_month_cos': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float64>, 'first_started_day': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int64>, 'first_started_day_sin': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>, 'first_started_day_cos': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>, 'first_started_month': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int64>, 'first_started_month_sin': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float64>, 'first_started_month_cos': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float64>, 'first_started_year': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "66/66 [==============================] - 1s 7ms/step - loss: 1.9939 - accuracy: 0.4219 - val_loss: 1.5017 - val_accuracy: 0.5063\n",
      "Epoch 2/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.2038 - accuracy: 0.6574 - val_loss: 1.0664 - val_accuracy: 0.7215\n",
      "Epoch 3/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7925 - accuracy: 0.7941 - val_loss: 0.8037 - val_accuracy: 0.7932\n",
      "Epoch 4/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.8614 - val_loss: 0.6817 - val_accuracy: 0.8101\n",
      "Epoch 5/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8877 - val_loss: 0.6052 - val_accuracy: 0.8228\n",
      "Epoch 6/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.9226 - val_loss: 0.5608 - val_accuracy: 0.8565\n",
      "Epoch 7/8\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.9422 - val_loss: 0.5130 - val_accuracy: 0.8650\n",
      "Epoch 8/8\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9503 - val_loss: 0.5027 - val_accuracy: 0.8692\n"
     ]
    }
   ],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    feature_layer,\n",
    "    layers.Dense(80, input_dim=20, activation='relu'),\n",
    "    layers.Dense(40, activation='relu'),\n",
    "    layers.Dense(14, activation='softmax', name='i1_pred_label_id'),\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2121_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
